---
title: "Sprawozdanie 3"
author: "Katarzyna Rzeszutek, Karol Szpyt"
date: "10 stycznia 2020"
output: html_document
encoding: "utf - 8"
---
Zbiór danych na jakich będziemy pracowali zawiera 7 zmiennych - jedną objaśnianą Z1, oraz 6 zmiennych objaśniających (w tym 5 zmiennych numerycznych i jedną zmienną jakościową przybierającą wartości „small”, „medium” oraz „large”). Zbiór danych liczy 100 obserwacji.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(fastDummies)
library(lmtest)
library(car)
data <-  read.csv("DaneZ3.csv", sep = ";")
```


###Zadanie 1, 2 i 3
Nasz zbiór danych zostanie podzielony w sposób losowy. Wykorzystamy swój numer albumu jako ziarno generatora i podzielimy dane na 2 dwie części: jedna próbka *data.train * będzie liczyć 90 obserwacji, a *data.test* 10 obserwacji. Jednak zanim to zrobimy, zajmiemy się zmienną jakościową. Funkcją *dummy* zmiennę jakościową zamienimy na 3 zmienne binarne, gdzie 1 będzie odpowiadała posiadaniu danej cechy (*small*, *medium* lub *large*) przez obserwację. Jedną z kolumn należy usunąć, usuniemy *small*.
```{r echo=TRUE, message=FALSE, warning=FALSE}
#rozdzielenie zmiennej jakościowej na 3 zmienne binarne
dmmy <- dummy_cols(data$Z7)
data <- cbind(data[, 1:6], dmmy[, c(3, 2)])
colnames(data)[7:8] <- c("Z7.medium", "Z7.large")
#ziarno generatora
set.seed(293487)
#podział na zestaw uczący się i testowy
train.inx <- sample(1:100, 90)
data.train <- data[train.inx, ]
data.test <- data[-train.inx, ]
```
Dla modelu będziemy weryfikowali kilka własności, aby wykazać że jest on dobry:
  
  * współczynnik determinacji $R^2$
  
  * koincydencję
  
  * istotność parametrów strukturalnych - test t-Studenta 
  
  * istotność współczynnika determinacji
  
  * łączną istotność parametrów strukturalnych - test Walda
  
  * współliniowość - parametr VIF
  
  * heteroskedastyczność - 
  
  * !!!poprawną specyfikację modelu - test RESET
  
  * !!!czy postać funkcyjna modelu jest stabilna - test Chowa

Następnie wybierzemy odpowiednią postać modelu metodą Hellwiga

```{r echo=FALSE, message=FALSE, warning=FALSE}
hellwig <- function(y, x)
{
  n <- ncol(x)
  l <- (2^n)-1
  
  R0 <- cor(y, x)
  R <- abs(as.matrix(cor(x)))

  argument <- replicate(n, c(0, 1), simplify = FALSE)
  comb <- as.matrix(expand.grid(argument))
  comb <- comb[-1,]
  
  h <- matrix(0, l, n)
  
  for(i in 1:l) 
  {
    for(j in 1:n)
    {
      h[i,j] <- (comb[i, j] * (R0[j]^2))/ (comb[i,] %*% as.vector(R[,j]))
    }
  }

  
  m=which.max(rowSums(h))
  colnames(comb) <- colnames(x)
  
  return((comb[m,]))
}

#hellwig(zmienna_objaśniana, zmienna objaśniająca)
hellwig(data.train[, 1], data.train[, -1])
```
Metoda ta pokazała, że do modelu powinniśmy wziąć zmienne Z2, Z7.medium i Z7.large. Jednak nie możemy rozdzielić zmiennej Z7, zatem bierzemy Z7.medium i Z7.large do modelu
```{r echo=TRUE, message=FALSE, warning=FALSE}
model1 <- lm(Z1 ~ Z2 + Z7.medium + Z7.large, data.train)
summary(model1)
```
Następnie sprawdzimy koincydencję w modelu
```{r echo=TRUE, message=FALSE, warning=FALSE}
korelacje <- cor(data.train, method = "pearson")
korelacje[1, c(2,7,8)]
```
**Niestety nasz model okazał się być niekoincydentny**, zatem musimy dokonać pewnych modyfikacji. Spróbujemy wyestymować model nie biorąc pod uwagę zmiennych jakościowych
```{r echo=FALSE, message=FALSE, warning=FALSE}
hellwig <- function(y, x)
{
  n <- ncol(x)
  l <- (2^n)-1
  
  R0 <- cor(y, x)
  R <- abs(as.matrix(cor(x)))

  argument <- replicate(n, c(0, 1), simplify = FALSE)
  comb <- as.matrix(expand.grid(argument))
  comb <- comb[-1,]
  
  h <- matrix(0, l, n)
  
  for(i in 1:l) 
  {
    for(j in 1:n)
    {
      h[i,j] <- (comb[i, j] * (R0[j]^2))/ (comb[i,] %*% as.vector(R[,j]))
    }
  }

  
  m=which.max(rowSums(h))
  colnames(comb) <- colnames(x)
  
  return((comb[m,]))
}

#hellwig(zmienna_objaśniana, zmienna objaśniająca)
hellwig(data.train[, 1], data.train[, -c(1,7,8)])
```
Tym razem metoda Hellwiga wskazuje na zmienne Z2 i Z3, zatem wyestymujemy taki model
```{r echo=TRUE, message=FALSE, warning=FALSE}
model2 <- lm(Z1 ~ Z2 + Z3, data.train)
summary(model2)
```
  
  Sprawdzimy założenie o normalności reszt w celu weryfikacji istotności zmiennych w modelu za pomocą testu t - Studenta, którego hipotezy wyglądają następująco:
  
  *H0: Rozkład badanej cechy jest rozkładem normalnym*
  
  *H1: Rozkład badanej cechy nie jest rozkładem normalnym.*
```{r echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(model1$residuals)
```
P - value pokazało, że rozkład reszt jest rozkładem normalnym, zatem spełnione jest założenie testu t - Studenta. Jego hipotezy:
  
  *H0: dana zmienna nie oddziałuje istotnie na zmienną objaśnianą*
  
  *H0: dana zmienna  oddziałuje istotnie na zmienną objaśnianą.*
Pokazuje on, że wyraz wolny jest nieistotny, zatem usuniemy go ze swojego modelu.
```{r echo=TRUE, message=FALSE, warning=FALSE}
model3 <- lm(Z1 ~ Z2 + Z3 -1, data.train)
summary(model3)
```
Ponownie badamy rozkład  reszt, by móc oceniać istotność parametrów
```{r echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(model3$residuals)
```
  
Reszty naszego modelu są normalne, zatem możemy stwierdzić, że **każda ze zmiennych jest istotna** (na podstawie testu t-Studenta).
  
  **Współczynnik determinacji** naszego modelu to 0.71.
  
  **Współczynnik korelacji wielorakiej na podstawie testu F okazał się istotny**.
  
  Sprawdzimy koincydencję - W celu sprawdzenia czy model jest koincydentny sprawdzamy czy spełniony jest warunek 
$$sgn(r_{i}) = sgn(a_{i})$$ gdzie i = 1,2,,,,k. $a_{i}$ to oszacowanie parametru strukturalnego występującego przy zmiennej objaśniającej $X_{i}$, a $r_{i}$ jest współczynnikiem korelacji liniowej Pearsona między zmienną $X_{i}$ a $Y_{i}$
```{r echo=TRUE, message=FALSE, warning=FALSE}
korelacje <- cor(data.train, method = "pearson")
korelacje[1, c(2,3)]
```
**Model jest koincydentny**.
  
  Sprawdzimy łączną istotność parametrów strukturalnych testem Walda. Hipotezy:
  
  H0: $\beta_{1} = \beta_{2} = ... =\beta_{k} = 0$
  
  H1: $\beta_{1} = \beta_{2} = ... =\beta_{k}$ nie jest równe 0.
```{r echo=TRUE, message=FALSE, warning=FALSE}
waldtest(model3)
```
**Model ma łącznie istotne parametry**.
  
  Sprawdzimy czy w modelu zachodzi zjawisko współliniowości
```{r echo=TRUE, message=FALSE, warning=FALSE}
vif(model3)
```
Współliniowość oceniamy *czynnikiem inflacji wariancji* (VIF). Wskaźnik ten pokazuje ile razy wariancja predyktora jest większa od wartości niezakłóconej współliniowością, gdzie 1 jest najmniejszą możliwą wartością, a 10 największą. **W modelu nie ma zjawiska współliniowośći**.
  
  Sprawdzimy zjawisko heteroskedastyczności. Hipotezy:
  
  *H0: homoskedastyczność*
  
  *H1: 
```{r echo=TRUE, message=FALSE, warning=FALSE}
ncvTest(model3)
```
  













