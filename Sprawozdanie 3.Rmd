---
title: "Sprawozdanie 3"
author: "Katarzyna Rzeszutek, Karol Szpyt"
date: "10 stycznia 2020"
output: html_document
encoding: "utf - 8"
---
Zbiór danych na jakich będziemy pracowali zawiera 7 zmiennych - jedną objaśnianą Z1, oraz 6 zmiennych objaśniających (w tym 5 zmiennych numerycznych i jedną zmienną jakościową przybierającą wartości „small”, „medium” oraz „large”). Zbiór danych liczy 100 obserwacji.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(fastDummies)
library(lmtest)
library(car)
library(strucchange)
data <-  read.csv("DaneZ3.csv", sep = ";")
```


###Zadanie 1, 2 i 3
Nasz zbiór danych zostanie podzielony w sposób losowy. Wykorzystamy swój numer albumu jako ziarno generatora i podzielimy dane na 2 dwie części: jedna próbka *data.train * będzie liczyć 90 obserwacji, a *data.test* 10 obserwacji. Jednak zanim to zrobimy, zajmiemy się zmienną jakościową. Funkcją *dummy* zmiennę jakościową zamienimy na 3 zmienne binarne, gdzie 1 będzie odpowiadała posiadaniu danej cechy (*small*, *medium* lub *large*) przez obserwację. Jedną z kolumn należy usunąć, usuniemy *small*.
```{r echo=TRUE, message=FALSE, warning=FALSE}
#rozdzielenie zmiennej jakościowej na 3 zmienne binarne
dmmy <- dummy_cols(data$Z7)
data <- cbind(data[, 1:6], dmmy[, c(3, 2)])
colnames(data)[7:8] <- c("Z7.medium", "Z7.large")
#ziarno generatora
set.seed(293487)
#podział na zestaw uczący się i testowy
train.inx <- sample(1:100, 90)
data.train <- data[train.inx, ]
data.test <- data[-train.inx, ]
```
Dla modelu będziemy weryfikowali kilka własności, aby wykazać że jest on dobry:
  
  * współczynnik determinacji $R^2$
  
  * koincydencję
  
  * istotność parametrów strukturalnych - test t-Studenta 
  
  * istotność współczynnika determinacji - test Fishera-Snedecora
  
  * łączną istotność parametrów strukturalnych - test Walda
  
  * współliniowość - parametr VIF
  
  * heteroskedastyczność - test Breuscha Pagana, Harrisona-McCabea i Goldfelda-Quandta
  
  * poprawną specyfikację modelu - test RESET
  
  * czy postać funkcyjna modelu jest stabilna - test CUSUM (cumulated sum of residuals), zwanego także testem Harvey’a-Colliera

Następnie wybierzemy odpowiednią postać modelu metodą Hellwiga

```{r echo=FALSE, message=FALSE, warning=FALSE}
hellwig <- function(y, x)
{
  n <- ncol(x)
  l <- (2^n)-1
  
  R0 <- cor(y, x)
  R <- abs(as.matrix(cor(x)))

  argument <- replicate(n, c(0, 1), simplify = FALSE)
  comb <- as.matrix(expand.grid(argument))
  comb <- comb[-1,]
  
  h <- matrix(0, l, n)
  
  for(i in 1:l) 
  {
    for(j in 1:n)
    {
      h[i,j] <- (comb[i, j] * (R0[j]^2))/ (comb[i,] %*% as.vector(R[,j]))
    }
  }

  
  m=which.max(rowSums(h))
  colnames(comb) <- colnames(x)
  
  return((comb[m,]))
}

#hellwig(zmienna_objaśniana, zmienna objaśniająca)
hellwig(data.train[, 1], data.train[, -1])
```
Metoda ta pokazała, że do modelu powinniśmy wziąć zmienne Z2, Z7.medium i Z7.large. Jednak nie możemy rozdzielić zmiennej Z7, zatem bierzemy Z7.medium i Z7.large do modelu
```{r echo=TRUE, message=FALSE, warning=FALSE}
model1 <- lm(Z1 ~ Z2 + Z7.medium + Z7.large, data.train)
summary(model1)
```
Następnie sprawdzimy koincydencję w modelu - W tym celu sprawdzamy czy spełniony jest warunek 
$$sgn(r_{i}) = sgn(a_{i})$$ gdzie i = 1,2,,,,k. $a_{i}$ to oszacowanie parametru strukturalnego występującego przy zmiennej objaśniającej $X_{i}$, a $r_{i}$ jest współczynnikiem korelacji liniowej Pearsona między zmienną $X_{i}$ a $Y_{i}$
```{r echo=TRUE, message=FALSE, warning=FALSE}
korelacje <- cor(data.train, method = "pearson")
korelacje[1, c(2,7,8)]
```
**Niestety nasz model okazał się być niekoincydentny**, zatem musimy dokonać pewnych modyfikacji. Spróbujemy wyestymować model jeszcze raz (metodą Hellwiga) nie biorąc pod uwagę zmiennych jakościowych
```{r echo=FALSE, message=FALSE, warning=FALSE}
hellwig <- function(y, x)
{
  n <- ncol(x)
  l <- (2^n)-1
  
  R0 <- cor(y, x)
  R <- abs(as.matrix(cor(x)))

  argument <- replicate(n, c(0, 1), simplify = FALSE)
  comb <- as.matrix(expand.grid(argument))
  comb <- comb[-1,]
  
  h <- matrix(0, l, n)
  
  for(i in 1:l) 
  {
    for(j in 1:n)
    {
      h[i,j] <- (comb[i, j] * (R0[j]^2))/ (comb[i,] %*% as.vector(R[,j]))
    }
  }

  
  m=which.max(rowSums(h))
  colnames(comb) <- colnames(x)
  
  return((comb[m,]))
}

#hellwig(zmienna_objaśniana, zmienna objaśniająca)
hellwig(data.train[, 1], data.train[, -c(1,7,8)])
```
Tym razem metoda Hellwiga wskazuje na zmienne Z2 i Z3, zatem wyestymujemy taki model
```{r echo=TRUE, message=FALSE, warning=FALSE}
model2 <- lm(Z1 ~ Z2 + Z3, data.train)
summary(model2)
```
  
  Sprawdzimy założenie o normalności reszt w celu weryfikacji istotności zmiennych w modelu za pomocą testu t - Studenta, którego hipotezy wyglądają następująco:
  
  *H0: Rozkład badanej cechy jest rozkładem normalnym*
  
  *H1: Rozkład badanej cechy nie jest rozkładem normalnym.*
```{r echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(model1$residuals)
```
P - value pokazało, że rozkład reszt jest rozkładem normalnym, zatem spełnione jest założenie testu t - Studenta. Jego hipotezy:
  
  *H0: dana zmienna nie oddziałuje istotnie na zmienną objaśnianą*
  
  *H0: dana zmienna  oddziałuje istotnie na zmienną objaśnianą.*
  
  Pokazuje on, że wyraz wolny jest nieistotny, zatem usuniemy go ze swojego modelu.
```{r echo=TRUE, message=FALSE, warning=FALSE}
model3 <- lm(Z1 ~ Z2 + Z3 -1, data.train)
summary(model3)
```
Ponownie badamy rozkład  reszt, by móc oceniać istotność parametrów
```{r echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(model3$residuals)
```
  
Reszty naszego modelu są normalne, zatem możemy stwierdzić, że **każda ze zmiennych jest istotna** (na podstawie testu t-Studenta).
  
  **Współczynnik determinacji** naszego modelu to 0.71.
  
  **Współczynnik korelacji wielorakiej na podstawie testu F okazał się istotny**.
  
  Sprawdzimy koincydencję
```{r echo=TRUE, message=FALSE, warning=FALSE}
korelacje <- cor(data.train, method = "pearson")
korelacje[1, c(2,3)]
```
**Model jest koincydentny**.
  
  Sprawdzimy łączną istotność parametrów strukturalnych testem Walda. Hipotezy:
  
  H0: $\beta_{1} = \beta_{2} = ... =\beta_{k} = 0$ - parametry są łącznie nieistotne
  
  H1: $\beta_{1} = \beta_{2} = ... =\beta_{k}$ nie jest równe 0 - parametry są łącznie istotne
```{r echo=FALSE, message=FALSE, warning=FALSE}
waldtest(model3)
```
**Model ma łącznie istotne parametry**.
  
  Sprawdzimy czy w modelu zachodzi zjawisko współliniowości
```{r echo=FALSE, message=FALSE, warning=FALSE}
vif(model3)
```
Współliniowość oceniamy *czynnikiem inflacji wariancji* (VIF). Wskaźnik ten pokazuje ile razy wariancja predyktora jest większa od wartości niezakłóconej współliniowością, gdzie 1 jest najmniejszą możliwą wartością, a 10 największą. **W modelu nie ma zjawiska współliniowośći**.
  
  Sprawdzimy zjawisko heteroskedastyczności, dla pewności aż 3 testami. Hipotezy:
  
  *H0: homoskedastyczność składnika losowego*
  
  *H1: heteroskedastyczność składnika losowego*
```{r echo=FALSE, message=FALSE, warning=FALSE}
ncvTest(model3)
hmctest(model3)
gqtest(model3)
```
Przyjmujemy hipotezę zerową dla każdego z testów - **reszty naszego modelu są homoskedastyczne**.


###Zadanie 4
  Aby można było dokonywać predykcji na modelu musi on spełniać warunki takie jak pozytywna weryfikacja oraz stabilne relacje między zmiennymi - poprawna specyfikacja modelu, stabilność parametrów i rozkład składnika losowego, który spełnia założenia MNK i ma normalne reszty (co dowiedliśmy). Sprawdzimy najpierw poprawną specyfikację modelu za pomocą testu RESET. Hipotezy:
  *H0: wybór postaci analitycznej modelu jest prawidłowy,*
  
  *H1: wybór postaci analitycznej modelu nie jest prawidłowy,*
  
```{r echo=FALSE, message=FALSE, warning=FALSE}
resettest(model3)
```
Przyjmujemy hipotezę zerową, że nasz **model ma poprawną specyfikację modelu**.
  
  Stabilność parametrów sprawdzimy za pomocą testu CUSUM (cumulated sum of residuals), zwanego także testem Harvey’a-Colliera. Hipotezy:
  H0: parametry są stabilne
  
  H0: parametry nie są stabilne
```{r echo=FALSE, message=FALSE, warning=FALSE}
harvtest(model3)
```
Na jego podstawie uznajemy, że **parametry modelu są stabilne**. Na podstawie tych 2 dowiedzionych własności wiemy, że **na podstawie otrzymanego modelu można dokonywać prognozy**.

###Zadanie 5
Wyznaczymy prognozę punktową oraz 95% przedział ufności dla podanych wartości
```{r echo=TRUE, message=FALSE, warning=FALSE}
df.pr <- data.frame(-10.5, 8, 51.7, 12.8, 94.6, 0, 0, 1)
names(df.pr) <- names(data)[-1]
pred1 <- predict(model3, newdata = df.pr, interval = 'confidence')
```
Prognoza punktowa dla tego zestawu zmiennych wyniosła -12.1217, a przedziały ufności od -17.76622 do -6.477184.

###Zadanie 6
Wykorzystując podzbiór testowy dokonamy prognozy EX POST dla tych obserwacji i dla każdej obserwacji obliczymy różnicę pomiędzy rzeczywistą wartością zmiennej Z1, a jej wartością prognostyczną
```{r echo=TRUE, message=FALSE, warning=FALSE}
pred <- predict(model3, newdata = data.test, interval = 'confidence')
#różnice pomiędzy rzeczywistą wartością Z1 a prognozowaną - to na pewno dobrze?
diff <- data$Z1 - pred[, 1]
#nie wiem co ten wykres przedstawia
plot(pred, type = "l")
lines(data.test$Z1, col = "red")
#wykres wartości rzeczywistych Z1 (na czarno) i przewidywanych (na czerwono)
plot(data.test$Z1, type = "l")
lines(pred[, 1], col = "red")
```

###Zadanie 7
Dla prognoz z zadania 6 obliczymy średni błąd predykcji EX POST. Im jest on bliższy 0 tym prognoza była dokładniejsza.
```{r echo=TRUE, message=FALSE, warning=FALSE}
err <- function(real, pred)
{
  mean(real - pred)
}
err(data$Z1, pred[, 1])
```
Przeciętne obciążenie prognozy to -17.33737, co wskazuje na to, że prognozy wygasłe były przeszacowane. Opisz w jakich sytuacjach stosowanie tego błędy w analizach jest niewskazane?

###Zadanie 8
Dla prognoz z zadania 6 obliczymy średni bezwzględny błąd predykcji EX POST, który podaje w jednostkach bezwzględnych, o ile średnio prognoza różni się od wartości rzeczywistej
```{r echo=TRUE, message=FALSE, warning=FALSE}
err.bwzg <- function(real, pred)
{
  mean(abs(real - pred))
}
err.bwzg(data$Z1, pred[, 1])
```
Rzeczywiste relacje zmiennej prognozowanej
będą się odchylać o 50.81189 od prognoz.

Różnica pomiędzy tym błędem, a błędem z zadania 7 (zakładając, że obserwacje są szeregiem czasowym) wskazuje na ?
```{r echo=TRUE, message=FALSE, warning=FALSE}
err.bwzg(data$Z1, pred[, 1]) - err(data$Z1, pred[, 1])
```

###Zadanie 9
Dla prognoz z zadania 6 obliczymy średniokwadratowy błąd predykcji EX POST
```{r echo=TRUE, message=FALSE, warning=FALSE}
err.sr.kw <- function(real, pred)
{
  mean((real - pred)^2)
}

err.sr.kw(data$Z1, pred[, 1])

```
Średniokwadratowy błąd predykcji EX POST wynosi 4130.407.
Opisz w jakich sytuacjach wskazane jest stosowanie błędu z zadania 8, a w jakich tego obliczonego w tym zadaniu?

###Zadanie 10
Dla prognoz z zadania 6 obliczymy średni bezwzględny procentowy błąd predykcji EX POST. Zakładając, że opracowanie modelu prognostycznego było zleceniem wykonywanym na potrzeby pewnej firmy, która w umowie zawarła klauzulę, że błąd MAPE nie powinien przekroczyć 5%, ocenimy czy stworzony przez zespół model spełnia to wymaganie.
  
  Błąd MAPE podaje o ile procent średnio prognoza różni się od wartości rzeczywistej. Błędy średnie wyznacza się wtedy, gdy znana jest już rzeczywista wartość zmiennej prognozowanej i są one miarą różnicy między wartością prognozy i zaobserwowaną wartością zmiennej prognozowanej.
```{r echo=TRUE, message=FALSE, warning=FALSE}
MAPE <- function(real, pred)
{
  mean(abs((real - pred)/real))*100
}

MAPE(data$Z1, pred[, 1])
```















